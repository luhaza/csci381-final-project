{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "from torch import Generator\n",
    "from torch import optim\n",
    "from model import LightGCN, train_model\n",
    "# from model2 import LightGCN\n",
    "from representations import convert_to_adj_matrix, convert_to_dense_adj_matrix, extract_interaction_matrix\n",
    "from preprocessing import dataset, init_interaction_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 610 users and 9724 movies in this dataset. \n",
    "* On average, users give a movie a 3.5/5 rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>1.008360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>325.127564</td>\n",
       "      <td>3101.735561</td>\n",
       "      <td>3.501557</td>\n",
       "      <td>1.205946e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>182.618491</td>\n",
       "      <td>2627.050983</td>\n",
       "      <td>1.042529</td>\n",
       "      <td>2.162610e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.281246e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.019124e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>324.000000</td>\n",
       "      <td>2252.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.186087e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>476.000000</td>\n",
       "      <td>5095.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.435994e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>609.000000</td>\n",
       "      <td>9723.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.537799e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
       "mean      325.127564    3101.735561       3.501557  1.205946e+09\n",
       "std       182.618491    2627.050983       1.042529  2.162610e+08\n",
       "min         0.000000       0.000000       0.500000  8.281246e+08\n",
       "25%       176.000000     900.000000       3.000000  1.019124e+09\n",
       "50%       324.000000    2252.000000       3.500000  1.186087e+09\n",
       "75%       476.000000    5095.250000       4.000000  1.435994e+09\n",
       "max       609.000000    9723.000000       5.000000  1.537799e+09"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users: 610, movies: 7364\n"
     ]
    }
   ],
   "source": [
    "threshold = 3.5\n",
    "dataset = dataset.where(dataset[\"rating\"] >= threshold)\n",
    "num_users = len(dataset[\"userId\"].unique())\n",
    "num_movies = len(dataset[\"movieId\"].unique())\n",
    "\n",
    "print(f\"users: {num_users}, movies: {num_movies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create the graph__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
      "        [   0,    2,    5,  ..., 9443, 9444, 9445]]) torch.Size([2, 61716])\n",
      "tensor([4., 4., 4.,  ..., 5., 5., 5.], dtype=torch.float64) torch.Size([61716])\n",
      "tensor(3.5000, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "locations, values = init_interaction_edges(dataset, \"userId\", \"movieId\", \"rating\", threshold)\n",
    "\n",
    "print(locations, locations.size())\n",
    "print(values, values.size())\n",
    "print(values.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges: 61716, nodes: 7974\n"
     ]
    }
   ],
   "source": [
    "num_interactions = values.shape[0]\n",
    "\n",
    "print(f\"edges: {num_interactions}, nodes: {num_movies+num_users}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Split into test and train sets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 49373 interactions\n",
      "test: 12343 interactions\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(num_interactions))\n",
    "\n",
    "generator = Generator().manual_seed(42)\n",
    "train_set_split, test_set_split = random_split(indices, [0.8, 0.2], generator=generator)\n",
    "\n",
    "print(f\"train: {len(train_set_split)} interactions\")\n",
    "print(f\"test: {len(test_set_split)} interactions\")\n",
    "print((num_interactions) == (len(train_set_split) + len(test_set_split)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  94,   17,  248,  ...,  609,   73,  314],\n",
      "        [1497, 7243,  461,  ..., 7233, 2789,  974]]) torch.Size([2, 12343])\n",
      "tensor([4.0000, 4.5000, 4.5000,  ..., 4.5000, 4.5000, 4.0000],\n",
      "       dtype=torch.float64) torch.Size([12343])\n"
     ]
    }
   ],
   "source": [
    "train_indices = locations[:, train_set_split]\n",
    "train_values = values[train_set_split]\n",
    "\n",
    "test_indices = locations[:, test_set_split]\n",
    "test_values = values[test_set_split]\n",
    "\n",
    "print(test_indices, test_indices.size())\n",
    "print(test_values, test_values.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[    0,     0,     0,  ..., 10330, 10332, 10333],\n",
      "        [  610,   612,   615,  ...,   183,   183,   330]]), tensor([3.5000, 3.5000, 3.5000,  ..., 4.5000, 4.5000, 4.0000]))\n",
      "(tensor([[    0,     0,     0,  ..., 10323, 10326, 10331],\n",
      "        [  699,   935,   994,  ...,   183,   183,   183]]), tensor([4., 4., 4.,  ..., 4., 4., 4.]))\n"
     ]
    }
   ],
   "source": [
    "# 610, 9724 are the original counts\n",
    "\n",
    "train_set = convert_to_adj_matrix(train_indices, 610, 9724, train_values)\n",
    "test_set = convert_to_adj_matrix(test_indices, 610, 9724, test_values)\n",
    "\n",
    "print(train_set)\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 10000\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1024\n",
    "LR = 1e-3\n",
    "ITERS_PER_EVAL = 200\n",
    "ITERS_PER_LR_DECAY = 200\n",
    "K = 10\n",
    "LAMBDA = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[    0,     0,     0,  ..., 10330, 10332, 10333],\n",
       "                       [  610,   612,   615,  ...,   183,   183,   330]]),\n",
       "       values=tensor([3.5000, 3.5000, 3.5000,  ..., 4.5000, 4.5000, 4.0000]),\n",
       "       size=(10334, 10334), nnz=98746, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightGCN(num_users, num_movies)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}.\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "\n",
    "locations = locations.to(device)\n",
    "train_set_ind = train_set[0]\n",
    "train_set_ind = train_set_ind.to(device)\n",
    "train_set_sparse = torch.sparse_coo_tensor(indices=train_set_ind, values=train_set[1], size=(10334, 10334))\n",
    "type(train_set_sparse)\n",
    "# train_sparse = torch.sparse_coo_tensor(TRAIN_IND, TRAIN_VAL, size=(num_users+num_movies, num_users+num_movies))\n",
    "# print(train_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`MessagePassing.propagate` only supports integer tensors of shape `[2, num_messages]`, `torch_sparse.SparseTensor` or `torch.sparse.Tensor` for argument `edge_index`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train_edge_im, train_val_im = extract_interaction_matrix(TRAIN_IND, TRAIN_VAL, num_users, num_movies)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# validation_edge_im, validation_val_im = extract_interaction_matrix(VALIDATION_IND, VALIDATION_VAL, num_users, num_movies)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# test_edge_im, test_val_im = extract_interaction_matrix(TEST_IND, TEST_VAL, num_users, num_movies)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set_sparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cs381/final-project/csci381-final-project/code/model.py:137\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, device, optimizer, scheduler, train_set, train_set_sparse)\u001b[0m\n\u001b[1;32m    134\u001b[0m training_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(ITERATIONS)):\n\u001b[0;32m--> 137\u001b[0m     u_k, u_0, i_k, i_0 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set_sparse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     u, pos, neg \u001b[38;5;241m=\u001b[39m pos_neg_minibatch(BATCH_SIZE, train_set)\n\u001b[1;32m    140\u001b[0m     things \u001b[38;5;241m=\u001b[39m [u, pos, neg]\n",
      "File \u001b[0;32m~/cs381/final-project/csci381-final-project/code/model.py:56\u001b[0m, in \u001b[0;36mLightGCN.forward\u001b[0;34m(self, edge_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# for each layer, propagate\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# emb0 is the only trainable embedding\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     embk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memb0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     embs\u001b[38;5;241m.\u001b[39mappend[embk]\n\u001b[1;32m     59\u001b[0m embs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(embs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/var/folders/qh/5p13v2wd01x6bn0_xh36spzh0000gn/T/model_LightGCN_propagate_0ho7tgu7.py:105\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, size)\u001b[0m\n\u001b[1;32m    102\u001b[0m             x \u001b[38;5;241m=\u001b[39m hook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# End Propagate Forward Pre Hook ###########################################\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m mutable_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m fuse \u001b[38;5;241m=\u001b[39m is_sparse(edge_index) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuse\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fuse:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# Begin Message and Aggregate Forward Pre Hook #########################\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch_geometric/nn/conv/message_passing.py:290\u001b[0m, in \u001b[0;36mMessagePassing._check_input\u001b[0;34m(self, edge_index, size)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have size \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe first dimension (got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(size) \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    291\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`MessagePassing.propagate` only supports integer tensors of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    292\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape `[2, num_messages]`, `torch_sparse.SparseTensor` or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    293\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`torch.sparse.Tensor` for argument `edge_index`.\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: `MessagePassing.propagate` only supports integer tensors of shape `[2, num_messages]`, `torch_sparse.SparseTensor` or `torch.sparse.Tensor` for argument `edge_index`."
     ]
    }
   ],
   "source": [
    "# train_edge_im, train_val_im = extract_interaction_matrix(TRAIN_IND, TRAIN_VAL, num_users, num_movies)\n",
    "# validation_edge_im, validation_val_im = extract_interaction_matrix(VALIDATION_IND, VALIDATION_VAL, num_users, num_movies)\n",
    "# test_edge_im, test_val_im = extract_interaction_matrix(TEST_IND, TEST_VAL, num_users, num_movies)\n",
    "\n",
    "train_model(model, device, optimizer, scheduler, train_set_ind, train_set_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.sparse_coo_tensor([[1,2], [3,4]])\n",
    "type(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
